# Model Artifact Paths - Setup & Resolution

## Current Structure

To keep the repo lean, model artifacts are **not committed to Git** but are stored locally in multiple locations to support different execution contexts:

### Local Paths (Your Machine)
- **Primary artifacts location:** `models_artifacts/forecast_models/`
  - Trained Prophet forecasting models (10 cluster models)
  - Trained KMeans model
  - Generated by: `python src/models/forecast.py` and `python src/models/cluster.py`

- **Simulation runtime location:** `models/forecast_models/`
  - Copy of artifacts (synced locally for Docker container access)
  - Used by: `src/simulation/dynamic_sim.py` and `src/simulation/baseline_sim.py`
  - This is a workaround to ensure Docker containers can find the files

### Docker Container Paths
- **Expected path in container:** `/app/models_artifacts/forecast_models/`
- **Working path in container:** `/app/models/forecast_models/` (current workaround)

## Execution Contexts

### 1. Running Simulations (Docker)
```powershell
docker compose run --rm web python src/simulation/dynamic_sim.py
```
- Container looks for: `models/forecast_models/` (relative path)
- Files are mounted from local `models/forecast_models/` directory

### 2. Running Notebooks (Jupyter)
The notebook now supports **multiple path resolution** automatically:

1. Try local relative path: `models_artifacts/forecast_models/`
2. Try Docker container path: `/app/models_artifacts/forecast_models/`
3. Try notebook-relative path: `../../../models_artifacts/forecast_models/`

This means the notebook works both:
- **Locally:** `jupyter notebook` (looks for local `models_artifacts/`)
- **In Docker:** Jupyter lab/hub container (looks for `/app/models_artifacts/`)

### 3. Running Python Scripts Directly
```powershell
python src/models/forecast.py    # Generates models in models_artifacts/
python src/simulation/dynamic_sim.py  # Expects models/ or models_artifacts/
```

## Setup Checklist

✅ Models are generated automatically when you run:
```powershell
docker compose run --rm web python src/models/forecast.py
```

✅ Models are copied to the Docker-accessible path:
```powershell
# This happens automatically after generation
# But if you manually copy models, use:
Copy-Item -Path "models_artifacts/forecast_models/*" -Destination "models/forecast_models/" -Force
```

✅ Simulations can then run:
```powershell
docker compose run --rm web python src/simulation/dynamic_sim.py
```

## If Models Are Missing

**Quick Fix:**
```powershell
# Regenerate models
docker compose run --rm web python src/models/forecast.py

# Then copy to models/ for simulation access
Copy-Item -Path "models_artifacts/forecast_models/*" -Destination "models/forecast_models/" -Force
```

**Better Fix (One-Step):**
Create a setup script that auto-syncs artifacts (recommended for future improvements).

## Future Improvements

To fully resolve this, we could:
1. **Update `docker-compose.yml`** to mount `models_artifacts/` directly into the container
2. **Create a sync script** that auto-copies artifacts after model training
3. **Standardize on one path** across all execution contexts

Current approach ensures:
- ✅ Repo stays small (artifacts not in Git)
- ✅ Works locally with Python
- ✅ Works in Docker containers
- ✅ Notebooks auto-detect model locations
